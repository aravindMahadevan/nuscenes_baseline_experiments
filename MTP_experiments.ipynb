{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.eval.prediction.config import load_prediction_config\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.prediction.models.physics import ConstantVelocityHeading, PhysicsOracle\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
    "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
    "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
    "from nuscenes.prediction.models.backbone import ResNetBackbone\n",
    "from nuscenes.prediction.models.mtp import MTP, MTPLoss\n",
    "from nuscenes.prediction.models.covernet import CoverNet, ConstantLatticeLoss\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.eval.prediction.data_classes import Prediction\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/armahade/ECE285/AV/final_proj/MTP_experiments/maps'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), 'maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 32.1 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 8.3 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from nuscenes import NuScenes\n",
    "\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.eval.prediction.config import load_prediction_config\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.prediction import PredictHelper\n",
    "\n",
    "from nuscenes.prediction.models.physics import ConstantVelocityHeading, PhysicsOracle\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
    "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
    "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "class NuscenesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 nusc,\n",
    "                 helper,\n",
    "                 maps_dir,\n",
    "                 save_maps_dataset = False, \n",
    "                 config_name = 'predict_2020_icra.json',\n",
    "                 history=1, \n",
    "                 in_agent_frame=True):\n",
    "        \n",
    "        \n",
    "        self.nusc = nusc\n",
    "        self.helper = helper\n",
    "        \n",
    "        #initialize the data set \n",
    "        if maps_dir == 'maps_train':\n",
    "            dataset_version = \"train\"\n",
    "        elif maps_dir == 'maps_val':\n",
    "            dataset_version = \"val\"\n",
    "        \n",
    "        #initialize maps directory where everything will be saved \n",
    "        self.maps_dir = os.path.join(os.getcwd(), maps_dir)\n",
    "\n",
    "        self.data_set = get_prediction_challenge_split(dataset_version,dataroot=self.nusc.dataroot)\n",
    "\n",
    "        #initialize rasterizers for map generation\n",
    "        self.static_layer_rasterizer = StaticLayerRasterizer(self.helper)\n",
    "        self.agent_rasterizer = AgentBoxesWithFadedHistory(self.helper, seconds_of_history=history)\n",
    "        self.mtp_input_representation = InputRepresentation(self.static_layer_rasterizer, self.agent_rasterizer, Rasterizer())\n",
    "\n",
    "        self.in_agent_frame = in_agent_frame\n",
    "\n",
    "        self.config = load_prediction_config(self.helper, config_name)\n",
    "\n",
    "        self.valid_data_points = []\n",
    "        \n",
    "        self.save_maps_dataset = save_maps_dataset\n",
    "        \n",
    "        if self.save_maps_dataset: \n",
    "            self.save_maps()\n",
    "            \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "            \n",
    "    def save_maps(self):\n",
    "        '''\n",
    "        Input: None \n",
    "        Output: None\n",
    "        \n",
    "        This method finds all the valid data points in the data set. We define a valid data point \n",
    "        where the velocity, acceleartion, and heading specified by token not NaN. \n",
    "        '''\n",
    "        print(\"starting to save maps\")\n",
    "        for i, token in enumerate(self.data_set): \n",
    "            instance_token_img, sample_token_img = self.data_set[i].split('_')\n",
    "            \n",
    "            file_path = os.path.join(self.maps_dir, \"maps_{0}.jpg\".format(i))\n",
    "            \n",
    "            instance_token_img, sample_token_img = self.data_set[i].split('_')\n",
    "            img = self.mtp_input_representation.make_input_representation(instance_token_img, sample_token_img)\n",
    "            im = Image.fromarray(img)\n",
    "            im.save(file_path)\n",
    "        \n",
    "            print(\"{0}/{1} image saved\".format(i, len(self.data_set)))\n",
    "        \n",
    "        print(\"done saving maps\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_set)\n",
    "    \n",
    "    #return the image tensor, agent state vector, and the ground truth\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        instance_token_img, sample_token_img = self.data_set[index].split('_')\n",
    "        \n",
    "        velocity = self.helper.get_velocity_for_agent(instance_token_img, sample_token_img)\n",
    "        acceleration = self.helper.get_acceleration_for_agent(instance_token_img, sample_token_img)\n",
    "        heading = self.helper.get_heading_change_rate_for_agent(instance_token_img, sample_token_img)        \n",
    "\n",
    "        #using a padding token of -1\n",
    "        if np.isnan(velocity) or np.isnan(acceleration) or np.isnan(heading):\n",
    "            velocity =  acceleration = heading = -1 \n",
    "\n",
    "        #construct agent state vector \n",
    "        agent_state_vec = torch.Tensor([velocity, acceleration, heading])\n",
    "        \n",
    "        #change image from (3, N, N), will have data loader take care \n",
    "        #get image and construct tensor \n",
    "        file_path = os.path.join(self.maps_dir, \"maps_{0}.jpg\".format(index))\n",
    "        \n",
    "        im = Image.open(file_path)\n",
    "        img = np.array(im)\n",
    "        image_tensor = torch.Tensor(img).permute(2, 0, 1)\n",
    "        \n",
    "        #get ground truth \n",
    "        ground_truth = self.helper.get_future_for_agent(instance_token_img, \n",
    "                                                        sample_token_img,\n",
    "                                                        self.config.seconds, \n",
    "                                                        in_agent_frame=self.in_agent_frame)\n",
    "        \n",
    "        ground_truth = torch.Tensor(ground_truth).unsqueeze(0)\n",
    "        return image_tensor, agent_state_vec, ground_truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle = True, pin_memory = True, num_workers = 4)\n",
    "\n",
    "#init network \n",
    "count = 0 \n",
    "M = 20\n",
    "backbone = ResNetBackbone('resnet50')\n",
    "mtp = MTP(backbone, num_modes=M).to(device)\n",
    "\n",
    "# covernet = CoverNet(backbone, num_modes=64).to(device)\n",
    "#init loss function and optimizers\n",
    "# criterion = ConstantLatticeLoss(trajectories)\n",
    "\n",
    "criterion = MTPLoss(num_modes=M)\n",
    "optimizer = optim.Adam(mtp.parameters(), lr=3e-4)\n",
    "\n",
    "output_dir = '.'\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(current_time)\n",
    "losses = []\n",
    "print('starting 100 epochs')\n",
    "print('total batches:' + str(len(dataloader)))\n",
    "for i in range(1):\n",
    "    epoch_loss = 0 \n",
    "    count = 0 \n",
    "    for image_tensor, agent_vec, ground_truth in dataloader:\n",
    "        output = mtp(image_tensor.to(device), agent_vec.to(device))\n",
    "        loss = criterion(output, ground_truth.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count+=1\n",
    "        epoch_loss+=loss\n",
    "        print(\"{0}/{1} loss is: {2}\".format(count + 1, len(dataloader), loss))\n",
    "        \n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import map rasterizer for agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 39.9 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 17.9 seconds.\n",
      "======\n",
      "static_layers.py - Loading Map: singapore-queenstown\n",
      "static_layers.py - Loading Map: singapore-hollandvillage\n",
      "static_layers.py - Loading Map: boston-seaport\n",
      "static_layers.py - Loading Map: singapore-onenorth\n"
     ]
    }
   ],
   "source": [
    "#import config from\n",
    "from nuscenes.eval.prediction.config import PredictionConfig, load_prediction_config\n",
    "baseDir = '../full_data/sets/nuscenes'\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=baseDir, verbose=True)\n",
    "helper = PredictHelper(nusc)\n",
    "val = get_prediction_challenge_split(\"train\", dataroot='../full_data/sets/nuscenes')\n",
    "config_name = 'predict_2020_icra.json'\n",
    "config = load_prediction_config(helper, config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mtp_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(predictions: List[Dict[str, Any]],\n",
    "                    helper: PredictHelper, config: PredictionConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Computes metrics from a set of predictions.\n",
    "    :param predictions: List of prediction JSON objects.\n",
    "    :param helper: Instance of PredictHelper that wraps the nuScenes val set.\n",
    "    :param config: Config file.\n",
    "    :return: Metrics. Nested dictionary where keys are metric names and value is a dictionary\n",
    "        mapping the Aggregator name to the results.\n",
    "    \"\"\"\n",
    "    n_preds = len(predictions)\n",
    "    containers = {metric.name: np.zeros((n_preds, metric.shape)) for metric in config.metrics}\n",
    "    for i, prediction_str in enumerate(predictions):\n",
    "        prediction = Prediction.deserialize(prediction_str)\n",
    "        ground_truth = helper.get_future_for_agent(prediction.instance, prediction.sample,\n",
    "                                                   config.seconds, in_agent_frame=True)\n",
    "        for metric in config.metrics:\n",
    "            containers[metric.name][i] = metric(ground_truth, prediction)\n",
    "    aggregations: Dict[str, Dict[str, List[float]]] = defaultdict(dict)\n",
    "    for metric in config.metrics:\n",
    "        for agg in metric.aggregators:\n",
    "            aggregations[metric.name][agg.name] = agg(containers[metric.name])\n",
    "    return aggregations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.load(open('mtp_preds.json', \"r\"))\n",
    "results = compute_metrics(predictions, helper, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'MinFDEK': {'RowMean': [20.517854563541597,\n",
       "               8.908261344616186,\n",
       "               8.908261344616186]},\n",
       "             'MinADEK': {'RowMean': [8.246023765371822,\n",
       "               4.338118872429088,\n",
       "               4.338118872429088]},\n",
       "             'MissRateTopK_2': {'RowMean': [0.9704678685986063,\n",
       "               0.9164915385466209,\n",
       "               0.9164915385466209]},\n",
       "             'OffRoadRate': {'RowMean': [1.0]}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = torch.Tensor(img).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "print(agent_state_vector)\n",
    "print(img.shape)\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output has 50 entries.\n",
    "# The first 24 are x,y coordinates (in the agent frame) over the next 6 seconds at 2 Hz for the first mode.\n",
    "# The second 24 are the x,y coordinates for the second mode.\n",
    "# The last 2 are the logits of the mode probabilities\n",
    "output = mtp(image_tensor, agent_state_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output[:,-M:]\n",
    "print(logits)\n",
    "probs = torch.softmax(logits, dim = 1)\n",
    "best_mode = torch.argmax(probs,dim=1).item()\n",
    "print(best_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_xy_local = helper.get_future_for_agent(instance_token_img, sample_token_img, seconds=6, in_agent_frame=False)\n",
    "future_xy_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_xy_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_xy_vec = future_xy_local.reshape(1, 24)\n",
    "future_xy_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape\n",
    "output[:,:-1].shapefu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_xy_vec - output[:,:-1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_xy_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
